{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "55beb66a623793bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:16.008244Z",
     "start_time": "2026-01-28T16:19:09.956896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from lightstream.core.scnn.scnn import StreamingCNN, StreamingConv2d"
   ],
   "id": "7de082ab3b85697",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:16.278138Z",
     "start_time": "2026-01-28T16:19:16.276130Z"
    }
   },
   "cell_type": "code",
   "source": "torch.set_printoptions(precision=10)",
   "id": "1136fd2dbe46173d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95718ab1767415d4"
  },
  {
   "cell_type": "code",
   "source": [
    "padding = 0\n",
    "\n",
    "stream_net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:17.813278Z",
     "start_time": "2026-01-28T16:19:17.779649Z"
    }
   },
   "id": "bd6f8d91181799c8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        layer.weight.data *= 1.0\n",
    "        \n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.zero_()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:18.528029Z",
     "start_time": "2026-01-28T16:19:18.525461Z"
    }
   },
   "id": "65a3d6c1f50a4d37",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "print(stream_net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:19.141788Z",
     "start_time": "2026-01-28T16:19:19.139560Z"
    }
   },
   "id": "2206f8e70f1d06de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (6): ReLU()\n",
      "  (7): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (8): ReLU()\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (11): ReLU()\n",
      "  (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (13): ReLU()\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configurations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6664c577e2c5beb"
  },
  {
   "cell_type": "code",
   "source": [
    "tile_size = 128*15\n",
    "img_size = 128*25\n",
    "\n",
    "cuda = True  # execute this notebook on the GPU\n",
    "verbose = True   # enable / disable logging\n",
    "dtype = torch.float64  # test with double precision"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:21.061187Z",
     "start_time": "2026-01-28T16:19:21.059115Z"
    }
   },
   "id": "7a0f0baa666c29c8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "stream_net.type(dtype)\n",
    "if cuda: stream_net.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:22.733930Z",
     "start_time": "2026-01-28T16:19:22.120374Z"
    }
   },
   "id": "f478abffc3ce9fdb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure streamingCNN\n",
    "IMPORTANT: setting gather_gradients to True makes the class save all the gradients of the intermediate feature maps. This is needed because we want to compare the feature map gradients between streaming and conventional backpropagation. However this also counteracts the memory gains by StreamingCNN. If you want to test the memory efficiency, set gather_gradients to False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d37d70c0d3421f13"
  },
  {
   "cell_type": "code",
   "source": [
    "sCNN = StreamingCNN(stream_net, \n",
    "                    tile_shape=(1, 3, tile_size, tile_size), \n",
    "                    verbose=True,\n",
    "                    saliency=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:25.707780Z",
     "start_time": "2026-01-28T16:19:25.016476Z"
    }
   },
   "id": "2cd870206b255a89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "\n",
      " Output lost Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "\n",
      "testing shape gradient fix\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:1.0, right:1.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:2.0, left:2.0, bottom:3.0, right:3.0)\n",
      "testing shape gradient fix\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:4.0, left:4.0, bottom:5.0, right:5.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:8.0, left:8.0, bottom:10.0, right:10.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:10.0, left:10.0, bottom:12.0, right:12.0)\n",
      "testing shape gradient fix\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:12.0, left:12.0, bottom:14.0, right:14.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:24.0, left:24.0, bottom:28.0, right:28.0)\n",
      "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:26.0, left:26.0, bottom:30.0, right:30.0)\n",
      "\n",
      " Input gradient lost Lost(top:28.0, left:28.0, bottom:32.0, right:32.0)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the verbose flag is True than StreamingCNN will print for every layer in the network the required overlap that is needed to reconstruct the feature maps and gradients. The higher this is, the more tiles are needed to be inferences. It is always beneficial to increase the tile size as much as possible to make use of all the GPU memory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cad5bbd0be54b30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate random image and fake label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "667550f1a8f6d206"
  },
  {
   "cell_type": "code",
   "source": [
    "image = torch.FloatTensor(3, img_size, img_size).normal_(0, 1)\n",
    "target = torch.tensor(50.)  # large value so we get larger gradients\n",
    "\n",
    "image = image.type(dtype)\n",
    "target = target.type(dtype)\n",
    "\n",
    "if cuda:\n",
    "    target = target.cuda()\n",
    "    image = image.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:30.372917Z",
     "start_time": "2026-01-28T16:19:30.068424Z"
    }
   },
   "id": "cc4e388db2427829",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = torch.nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:30.475536Z",
     "start_time": "2026-01-28T16:19:30.473351Z"
    }
   },
   "id": "1b9bc232937996ea",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run through network using streaming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c92cc440cd75645d"
  },
  {
   "cell_type": "code",
   "source": [
    "stream_output = sCNN.forward(image[None])\n",
    "print(stream_output.shape)\n",
    "stream_output.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:31.778873Z",
     "start_time": "2026-01-28T16:19:31.652717Z"
    }
   },
   "id": "14ee58248a07a1af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 396, 396])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0553336525, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "stream_output.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:36.093758Z",
     "start_time": "2026-01-28T16:19:36.091043Z"
    }
   },
   "id": "762fdcf9850c4c7b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "output = torch.sigmoid(torch.mean(stream_output)); output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:36.827392Z",
     "start_time": "2026-01-28T16:19:36.810781Z"
    }
   },
   "id": "a833c157e215563c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5024655418, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "loss = criterion(output, target)\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:37.977070Z",
     "start_time": "2026-01-28T16:19:37.961356Z"
    }
   },
   "id": "6081081438ef32f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2450.0059174429, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:39.566700Z",
     "start_time": "2026-01-28T16:19:39.546615Z"
    }
   },
   "id": "555dd52023b8fad8",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "print(stream_output.shape)\n",
    "print(stream_output.grad.shape)\n",
    "full_gradients = sCNN.backward(image[None], stream_output.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:44.235886Z",
     "start_time": "2026-01-28T16:19:40.651171Z"
    }
   },
   "id": "c2d36b3edafb4e6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 396, 396])\n",
      "torch.Size([1, 16, 396, 396])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "sCNN.saliency_map.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:53.473352Z",
     "start_time": "2026-01-28T16:19:53.469732Z"
    }
   },
   "id": "1acf48d6ac39e88b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3200, 3200])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "streaming_conv_gradients = []\n",
    "\n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, StreamingConv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            streaming_conv_gradients.append(layer.weight.grad.clone()) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:54.531985Z",
     "start_time": "2026-01-28T16:19:54.529274Z"
    }
   },
   "id": "9b4c6c1f339fa2e2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "sCNN.disable()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:55.863932Z",
     "start_time": "2026-01-28T16:19:55.859291Z"
    }
   },
   "id": "9caf49cce06c5f0e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare to conventional training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74e7c24c47c0bfcb"
  },
  {
   "cell_type": "code",
   "source": [
    "stream_net.type(dtype)\n",
    "if cuda: stream_net.cuda()\n",
    "\n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            layer.weight.grad.data.zero_()\n",
    "            layer.bias.grad.data.zero_()\n",
    "            \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:57.184636Z",
     "start_time": "2026-01-28T16:19:57.181246Z"
    }
   },
   "id": "f570eb5063cdd391",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "conventional_gradients = []\n",
    "inps = []\n",
    "\n",
    "def save_grad(module, grad_in, grad_out):\n",
    "    global conventional_gradients\n",
    "    conventional_gradients.append(grad_out[0].clone())\n",
    "        \n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        layer.register_backward_hook(save_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:19:57.874640Z",
     "start_time": "2026-01-28T16:19:57.871755Z"
    }
   },
   "id": "3b31e08e29427099",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "This output should be the same as the streaming output, if so, the loss will also be the same:\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76e88ba324844ae5"
  },
  {
   "cell_type": "code",
   "source": [
    "image.requires_grad = True\n",
    "conventional_output = stream_net(image[None]); conventional_output.max()\n",
    "conventional_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:00.374226Z",
     "start_time": "2026-01-28T16:20:00.362356Z"
    }
   },
   "id": "f6974420d6615a1e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 396, 396])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "print(conventional_output.shape)\n",
    "stream_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:03.430036Z",
     "start_time": "2026-01-28T16:20:03.426471Z"
    }
   },
   "id": "c29f896aa692a1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 396, 396])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 396, 396])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "# NOTE: sometimes output can be slightly bigger \n",
    "# (if tiles do not fit nicely on input image according to output stride)\n",
    "# In that case this check may fail.\n",
    "print(stream_output.shape, conventional_output.shape)\n",
    "max_error = torch.abs(stream_output.detach().cpu() - conventional_output.detach().cpu()).max().item()\n",
    "\n",
    "if max_error < 1e-7:\n",
    "    print(\"Equal output to streaming\")\n",
    "else:\n",
    "    print(\"NOT equal output to streaming\"),\n",
    "    print(\"error:\", max_error)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:09.181439Z",
     "start_time": "2026-01-28T16:20:09.141671Z"
    }
   },
   "id": "54e6961142a52c24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 396, 396]) torch.Size([1, 16, 396, 396])\n",
      "Equal output to streaming\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "output = torch.sigmoid(torch.mean(conventional_output)); output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:11.554234Z",
     "start_time": "2026-01-28T16:20:11.550104Z"
    }
   },
   "id": "dab0ce2d17f05bb8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5024655418, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "loss = criterion(output, target); loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:12.700204Z",
     "start_time": "2026-01-28T16:20:12.696458Z"
    }
   },
   "id": "c48adcad2f38750a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2450.0059174429, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:13.486246Z",
     "start_time": "2026-01-28T16:20:13.456595Z"
    }
   },
   "id": "fbb061cb856557d6",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "conventional_gradients[-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:14.382043Z",
     "start_time": "2026-01-28T16:20:14.379128Z"
    }
   },
   "id": "39c710f3672801ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 3198, 3198])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare the gradients of the input image\n",
    "Using the saliency argument, we can compute the gradient w.r.t to the input image. If streaming is the same as conventional training, these gradients should be roughly equal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6161a9b953a30d5c"
  },
  {
   "cell_type": "code",
   "source": [
    "diff = image.grad.detach().cpu().numpy() - sCNN.saliency_map[0].numpy()\n",
    "print(diff.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:17.591148Z",
     "start_time": "2026-01-28T16:20:17.316387Z"
    }
   },
   "id": "f5e23077c982b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3234889800848443e-22\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare the gradients of the conv2d layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fb109b0b711f846"
  },
  {
   "cell_type": "code",
   "source": [
    "normal_conv_gradients = []\n",
    "j = 0\n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            normal_conv_gradients.append(layer.weight.grad) \n",
    "            print('Conv layer', j, '\\t', layer)\n",
    "            j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:22.052475Z",
     "start_time": "2026-01-28T16:20:22.049438Z"
    }
   },
   "id": "df05ee0e7443ea52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer 0 \t Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 1 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 2 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 3 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 4 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 5 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "print('Conventional', '\\n')\n",
    "\n",
    "for i in range(len(streaming_conv_gradients)):\n",
    "    print(\"Conv layer\", i, \"\\t average gradient size:\", \n",
    "          float(torch.mean(torch.abs(streaming_conv_gradients[i].data))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:25.015924Z",
     "start_time": "2026-01-28T16:20:25.012524Z"
    }
   },
   "id": "7a564fe7a995e37b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional \n",
      "\n",
      "Conv layer 0 \t average gradient size: 0.005337106989303007\n",
      "Conv layer 1 \t average gradient size: 0.011621452477908677\n",
      "Conv layer 2 \t average gradient size: 0.016327254261941933\n",
      "Conv layer 3 \t average gradient size: 0.014050563924988376\n",
      "Conv layer 4 \t average gradient size: 0.012838129856554763\n",
      "Conv layer 5 \t average gradient size: 0.02153204154635157\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "print('Streaming', '\\n')\n",
    "for i in range(len(normal_conv_gradients)):\n",
    "    print(\"Conv layer\", i, \"\\t average gradient size:\", \n",
    "          float(torch.mean(torch.abs(normal_conv_gradients[i].data))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:27.790262Z",
     "start_time": "2026-01-28T16:20:27.786823Z"
    }
   },
   "id": "e7e4bd209a2a575b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming \n",
      "\n",
      "Conv layer 0 \t average gradient size: 0.005337106989303007\n",
      "Conv layer 1 \t average gradient size: 0.011621452477908679\n",
      "Conv layer 2 \t average gradient size: 0.01632725426194193\n",
      "Conv layer 3 \t average gradient size: 0.014050563924988388\n",
      "Conv layer 4 \t average gradient size: 0.012838129856554773\n",
      "Conv layer 5 \t average gradient size: 0.021532041546351636\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(len(streaming_conv_gradients)):\n",
    "    diff = torch.abs(streaming_conv_gradients[i].data - normal_conv_gradients[i].data)\n",
    "    max_diff = diff.max()\n",
    "    print(\"Conv layer\", i, \"\\t max difference between kernel gradients:\", \n",
    "          float(max_diff))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-28T16:20:30.316810Z",
     "start_time": "2026-01-28T16:20:30.312376Z"
    }
   },
   "id": "c91a1edbfbd9e631",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer 0 \t max difference between kernel gradients: 1.7416623698807143e-15\n",
      "Conv layer 1 \t max difference between kernel gradients: 3.802513859341161e-15\n",
      "Conv layer 2 \t max difference between kernel gradients: 5.405398351143731e-15\n",
      "Conv layer 3 \t max difference between kernel gradients: 5.703770789011742e-15\n",
      "Conv layer 4 \t max difference between kernel gradients: 9.020562075079397e-15\n",
      "Conv layer 5 \t max difference between kernel gradients: 3.552713678800501e-15\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6dd35762ef13fba8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
